"""
ç°¡åŒ–å ±å‘Šä»£ç† - ä½¿ç”¨ LLM è‡ªä¸»æ±ºç­–ç³»çµ±
é‡æ–°å¯¦ç¾ report_agent.py çš„å®Œæ•´åŠŸèƒ½ï¼Œæ¡ç”¨ç·šæ€§è™•ç†æµç¨‹å’Œæ™ºèƒ½æŸ¥è©¢è§£æ
æ‰€æœ‰è¨»è§£ã€æ–‡å­—å…§å®¹ã€æ—¥èªŒè¨Šæ¯ä½¿ç”¨ç¹é«”ä¸­æ–‡ (zh-TW)
"""
import logging
import re
import json
from datetime import datetime
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from pathlib import Path

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool

logger = logging.getLogger(__name__)

# å»¶é²å°å…¥çš„å…¨åŸŸè®Šæ•¸
_imports_loaded = False
_agent_tool_fmp_quote = None
_agent_tool_fmp_profile = None
_agent_tool_fmp_news = None
_agent_tool_fmp_macro = None
_agent_tool_rag_query = None
_analyze_data_with_llm = None
_build_analysis_prompt = None


def _ensure_imports():
    """ç¢ºä¿æ‰€æœ‰å¿…è¦çš„å°å…¥å·²è¼‰å…¥"""
    global _imports_loaded, _agent_tool_fmp_quote, _agent_tool_fmp_profile
    global _agent_tool_fmp_news, _agent_tool_fmp_macro, _agent_tool_rag_query
    global _analyze_data_with_llm, _build_analysis_prompt

    if _imports_loaded:
        return

    try:
        # å°å…¥è¨­å®š
        from app.settings import settings

        # å˜—è©¦å¾ agent_graph_simple å°å…¥å·¥å…·
        try:
            from app.graphs.agent_graph_simple import (
                tool_fmp_quote as agent_tool_fmp_quote,
                tool_fmp_profile as agent_tool_fmp_profile,
                tool_fmp_news as agent_tool_fmp_news,
                tool_fmp_macro as agent_tool_fmp_macro,
                tool_rag_query as agent_tool_rag_query
            )

            _agent_tool_fmp_quote = agent_tool_fmp_quote
            _agent_tool_fmp_profile = agent_tool_fmp_profile
            _agent_tool_fmp_news = agent_tool_fmp_news
            _agent_tool_fmp_macro = agent_tool_fmp_macro
            _agent_tool_rag_query = agent_tool_rag_query

            logger.info("æˆåŠŸå¾ agent_graph_simple å°å…¥å·¥å…·")

        except ImportError as e:
            logger.warning(f"ç„¡æ³•å¾ agent_graph_simple å°å…¥å·¥å…·ï¼Œä½¿ç”¨æœ¬åœ°å¯¦ç¾: {e}")
            # ä½¿ç”¨æœ¬åœ°å·¥å…·å¯¦ç¾
            _agent_tool_fmp_quote = tool_fmp_quote
            _agent_tool_fmp_profile = tool_fmp_profile
            _agent_tool_fmp_news = tool_fmp_news
            _agent_tool_fmp_macro = tool_fmp_macro
            _agent_tool_rag_query = tool_rag_query

        # è¨­å®š LLM åˆ†æå‡½æ•¸
        def _simple_analyze_data_with_llm(data, prompt):
            """ç°¡å–®çš„ LLM åˆ†æå‡½æ•¸"""
            return f"åŸºæ–¼å¯ç”¨è³‡æ–™çš„åˆ†æçµæœï¼š{str(data)[:200]}..."

        def _simple_build_analysis_prompt(symbols, data_type):
            """ç°¡å–®çš„åˆ†ææç¤ºå»ºæ§‹å‡½æ•¸"""
            return f"è«‹åˆ†æ {symbols} çš„ {data_type} è³‡æ–™"

        _analyze_data_with_llm = _simple_analyze_data_with_llm
        _build_analysis_prompt = _simple_build_analysis_prompt

        _imports_loaded = True
        logger.info("å°å…¥åˆå§‹åŒ–å®Œæˆ")

    except Exception as e:
        logger.error(f"å°å…¥åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        raise


# ===== æœ¬åœ°å·¥å…·å¯¦ç¾ (å‚™ç”¨) =====

@tool
async def tool_fmp_quote(symbols: List[str]) -> Dict[str, Any]:
    """FMP è‚¡ç¥¨å ±åƒ¹æŸ¥è©¢å·¥å…·"""
    logger.info(f"FMP å ±åƒ¹æŸ¥è©¢: {symbols}")

    try:
        from app.services.fmp_client import fmp_client

        if not symbols:
            return {
                "ok": False,
                "source": "FMP",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": "æœªæä¾›è‚¡ç¥¨ä»£è™Ÿ",
                "error": "missing_symbols"
            }

        result = await fmp_client.get_quote(symbols)

        return {
            "ok": result.get("ok", False),
            "source": "FMP",
            "data": result.get("data"),
            "timestamp": datetime.now().isoformat(),
            "logs": f"æŸ¥è©¢ {len(symbols)} å€‹è‚¡ç¥¨å ±åƒ¹",
            "error": result.get("reason") if not result.get("ok") else None
        }

    except Exception as e:
        logger.error(f"FMP å ±åƒ¹æŸ¥è©¢å¤±æ•—: {str(e)}")
        return {
            "ok": False,
            "source": "FMP",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"FMP å ±åƒ¹æŸ¥è©¢å¤±æ•—: {str(e)}",
            "error": "query_failed"
        }


@tool
async def tool_fmp_profile(symbols: List[str]) -> Dict[str, Any]:
    """FMP å…¬å¸åŸºæœ¬é¢æŸ¥è©¢å·¥å…·"""
    logger.info(f"FMP åŸºæœ¬é¢æŸ¥è©¢: {symbols}")

    try:
        from app.services.fmp_client import fmp_client

        if not symbols:
            return {
                "ok": False,
                "source": "FMP",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": "æœªæä¾›è‚¡ç¥¨ä»£è™Ÿ",
                "error": "missing_symbols"
            }

        result = await fmp_client.get_profile(symbols)

        return {
            "ok": result.get("ok", False),
            "source": "FMP",
            "data": result.get("data"),
            "timestamp": datetime.now().isoformat(),
            "logs": f"æŸ¥è©¢ {len(symbols)} å€‹å…¬å¸åŸºæœ¬é¢",
            "error": result.get("reason") if not result.get("ok") else None
        }

    except Exception as e:
        logger.error(f"FMP åŸºæœ¬é¢æŸ¥è©¢å¤±æ•—: {str(e)}")
        return {
            "ok": False,
            "source": "FMP",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"FMP åŸºæœ¬é¢æŸ¥è©¢å¤±æ•—: {str(e)}",
            "error": "query_failed"
        }


@tool
async def tool_fmp_news(symbols: Optional[List[str]] = None, limit: int = 10) -> Dict[str, Any]:
    """FMP æ–°èæŸ¥è©¢å·¥å…·"""
    logger.info(f"FMP æ–°èæŸ¥è©¢: symbols={symbols}, limit={limit}")

    try:
        from app.services.fmp_client import fmp_client

        result = await fmp_client.get_news(symbols=symbols, limit=limit)

        return {
            "ok": result.get("ok", False),
            "source": "FMP",
            "data": result.get("data"),
            "timestamp": datetime.now().isoformat(),
            "logs": f"æŸ¥è©¢ {limit} æ¢æ–°è",
            "error": result.get("reason") if not result.get("ok") else None
        }

    except Exception as e:
        logger.error(f"FMP æ–°èæŸ¥è©¢å¤±æ•—: {str(e)}")
        return {
            "ok": False,
            "source": "FMP",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"FMP æ–°èæŸ¥è©¢å¤±æ•—: {str(e)}",
            "error": "query_failed"
        }


@tool
async def tool_fmp_macro(indicators: List[str], limit: int = 6) -> Dict[str, Any]:
    """FMP ç¸½ç¶“æŒ‡æ¨™æŸ¥è©¢å·¥å…·"""
    logger.info(f"FMP ç¸½ç¶“æŸ¥è©¢: indicators={indicators}, limit={limit}")

    try:
        from app.services.fmp_client import fmp_client

        if not indicators:
            indicators = ["GDP", "CPI", "UNEMPLOYMENT"]

        macro_data = {}

        # é€å€‹æŸ¥è©¢æŒ‡æ¨™
        for indicator in indicators:
            try:
                result = await fmp_client.get_macro_data(indicator, "US")
                if result.get("ok"):
                    macro_data[f"{indicator}_US"] = result.get("data", [])
                else:
                    logger.warning(f"ç¸½ç¶“æŒ‡æ¨™ {indicator} æŸ¥è©¢å¤±æ•—: {result.get('reason')}")
                    macro_data[f"{indicator}_US"] = []
            except Exception as e:
                logger.error(f"ç¸½ç¶“æŒ‡æ¨™ {indicator} æŸ¥è©¢ç•°å¸¸: {str(e)}")
                macro_data[f"{indicator}_US"] = []

        return {
            "ok": True,
            "source": "FMP",
            "data": macro_data,
            "timestamp": datetime.now().isoformat(),
            "logs": f"æŸ¥è©¢ {len(indicators)} å€‹ç¸½ç¶“æŒ‡æ¨™",
            "error": None
        }

    except Exception as e:
        logger.error(f"FMP ç¸½ç¶“æŸ¥è©¢å¤±æ•—: {str(e)}")
        return {
            "ok": False,
            "source": "FMP",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"FMP ç¸½ç¶“æŸ¥è©¢å¤±æ•—: {str(e)}",
            "error": "query_failed"
        }


@tool
async def tool_rag_query(question: str, top_k: int = 5) -> Dict[str, Any]:
    """RAG æŸ¥è©¢å·¥å…·"""
    logger.info(f"RAG æŸ¥è©¢: {question}")

    try:
        from app.services.rag import rag_service

        query_result = await rag_service.query_documents(question, top_k)

        if query_result["ok"] and query_result["data"]["relevant_chunks"]:
            answer_result = await rag_service.answer_question(question, query_result["data"]["relevant_chunks"])
            return {
                "ok": answer_result.get("ok", False),
                "source": "RAG",
                "data": answer_result.get("data"),
                "timestamp": datetime.now().isoformat(),
                "logs": f"RAG æŸ¥è©¢å®Œæˆï¼Œæ‰¾åˆ° {len(query_result['data']['relevant_chunks'])} å€‹ç›¸é—œç‰‡æ®µ",
                "error": answer_result.get("reason") if not answer_result.get("ok") else None
            }
        else:
            return {
                "ok": False,
                "source": "RAG",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": "RAG æŸ¥è©¢æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”",
                "error": "no_relevant_documents"
            }

    except Exception as e:
        # å°‡ RAG å¤±æ•—å¾éŒ¯èª¤ç´šåˆ¥é™ç´šç‚ºè­¦å‘Šç´šåˆ¥
        logger.warning(f"RAG æŸ¥è©¢å¤±æ•—ï¼Œä½†ä¸å½±éŸ¿å ±å‘Šç”Ÿæˆ: {str(e)}")

        # æª¢æŸ¥éŒ¯èª¤é¡å‹
        error_type = "query_failed"
        if "shapes" in str(e) and "not aligned" in str(e):
            error_type = "vector_dimension_mismatch"
            logger.warning("æª¢æ¸¬åˆ°å‘é‡ç¶­åº¦ä¸åŒ¹é…éŒ¯èª¤ï¼Œé€™é€šå¸¸æ˜¯ RAG æœå‹™é…ç½®å•é¡Œ")
        elif "connection" in str(e).lower() or "timeout" in str(e).lower():
            error_type = "connection_failed"
            logger.warning("RAG æœå‹™é€£æ¥å¤±æ•—ï¼Œå¯èƒ½æœå‹™ä¸å¯ç”¨")

        return {
            "ok": False,
            "source": "RAG",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"RAG æŸ¥è©¢ä¸å¯ç”¨: {str(e)}",
            "error": error_type,
            "fallback_note": "RAG è³‡æ–™æºæš«æ™‚ä¸å¯ç”¨ï¼Œå ±å‘Šå°‡åŸºæ–¼å…¶ä»–å¯ç”¨è³‡æ–™æºç”Ÿæˆ"
        }


# ===== LLM é©…å‹•çš„æ™ºèƒ½æŸ¥è©¢è§£æ =====

async def parse_report_query_with_llm(query: str, llm=None) -> Dict[str, Any]:
    """ä½¿ç”¨ LLM æ™ºèƒ½è§£æå ±å‘ŠæŸ¥è©¢"""
    logger.info(f"ä½¿ç”¨ LLM è§£æå ±å‘ŠæŸ¥è©¢: {query}")

    if not llm:
        logger.warning("LLM æœªè¨­å®šï¼Œå›é€€åˆ°è¦å‰‡å¼è§£æ")
        return parse_report_query_fallback(query)

    try:
        # æ§‹å»ºçµæ§‹åŒ–æç¤º
        system_prompt = """ä½ æ˜¯å°ˆæ¥­çš„é‡‘èæŸ¥è©¢åˆ†æå¸«ã€‚è«‹åˆ†æç”¨æˆ¶çš„å ±å‘Šè«‹æ±‚ï¼Œä¸¦è¿”å›çµæ§‹åŒ–çš„ JSON éŸ¿æ‡‰ã€‚

è«‹æ ¹æ“šç”¨æˆ¶æŸ¥è©¢å…§å®¹ï¼Œæ™ºèƒ½åˆ¤æ–·ä»¥ä¸‹ä¿¡æ¯ï¼š
1. report_type: å ±å‘Šé¡å‹ ("stock", "macro", "news", "custom")
2. symbols: è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨ (å¦‚ ["AAPL", "TSLA"])
3. indicators: ç¸½ç¶“æŒ‡æ¨™åˆ—è¡¨ (å¦‚ ["GDP", "CPI", "UNEMPLOYMENT"])
4. keywords: é—œéµè©åˆ—è¡¨
5. confidence: åˆ¤æ–·ä¿¡å¿ƒåº¦ (0.0-1.0)

åˆ¤æ–·è¦å‰‡ï¼š
- å¦‚æœæåˆ°è‚¡ç¥¨ä»£è™Ÿã€å…¬å¸åç¨±ã€è‚¡ç¥¨åˆ†æ â†’ stock
- å¦‚æœæåˆ° GDPã€CPIã€é€šè†¨ã€å¤±æ¥­ç‡ã€ç¸½ç¶“ â†’ macro
- å¦‚æœæåˆ°æ–°èã€æ¶ˆæ¯ã€è³‡è¨Š â†’ news
- å…¶ä»–æƒ…æ³ â†’ custom

è«‹åªè¿”å› JSON æ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

        user_prompt = f"è«‹åˆ†æé€™å€‹å ±å‘Šè«‹æ±‚ï¼š{query}"

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]

        # èª¿ç”¨ LLM
        response = await llm.ainvoke(messages, temperature=0.1, max_tokens=500)

        # è§£æ JSON éŸ¿æ‡‰
        try:
            result = json.loads(response.content.strip())

            # é©—è­‰å¿…è¦æ¬„ä½
            if not isinstance(result, dict):
                raise ValueError("éŸ¿æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„å­—å…¸æ ¼å¼")

            # è¨­å®šé è¨­å€¼
            parsed_result = {
                "report_type": result.get("report_type", "custom"),
                "symbols": result.get("symbols", []),
                "indicators": result.get("indicators", []),
                "keywords": result.get("keywords", []),
                "confidence": result.get("confidence", 0.8),
                "parsing_method": "llm"
            }

            logger.info(f"LLM è§£æçµæœ: {parsed_result}")
            return parsed_result

        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"LLM éŸ¿æ‡‰è§£æå¤±æ•—: {e}, éŸ¿æ‡‰å…§å®¹: {response.content}")
            return parse_report_query_fallback(query)

    except Exception as e:
        logger.error(f"LLM æŸ¥è©¢è§£æå¤±æ•—: {str(e)}")
        return parse_report_query_fallback(query)


def parse_report_query_fallback(query: str) -> Dict[str, Any]:
    """è¦å‰‡å¼æŸ¥è©¢è§£æ (å‚™ç”¨æ–¹æ¡ˆ)"""
    logger.info(f"ä½¿ç”¨è¦å‰‡å¼è§£æå ±å‘ŠæŸ¥è©¢: {query}")

    # ç§»é™¤ /report å‰ç¶´
    content = query.replace("/report", "").strip()

    # é è¨­å€¼
    result = {
        "report_type": "custom",
        "symbols": [],
        "indicators": [],
        "keywords": [],
        "confidence": 0.6,
        "parsing_method": "fallback"
    }

    # æª¢æ¸¬å ±å‘Šé¡å‹
    if re.search(r'\b(stock|stocks|è‚¡ç¥¨|å€‹è‚¡|åˆ†æ)\b', content, re.IGNORECASE):
        result["report_type"] = "stock"
    elif re.search(r'\b(macro|ç¸½ç¶“|ç¶“æ¿Ÿ|gdp|cpi|inflation)\b', content, re.IGNORECASE):
        result["report_type"] = "macro"
    elif re.search(r'\b(news|æ–°è|æ¶ˆæ¯)\b', content, re.IGNORECASE):
        result["report_type"] = "news"

    # æå–è‚¡ç¥¨ä»£è™Ÿ
    symbols = re.findall(r'\b[A-Z]{2,5}\b', content.upper())
    exclude_words = {'STOCK', 'STOCKS', 'MACRO', 'NEWS', 'CUSTOM', 'REPORT', 'GDP', 'CPI'}
    valid_symbols = [s for s in symbols if s not in exclude_words]

    if valid_symbols and result["report_type"] == "custom":
        result["report_type"] = "stock"
        logger.info(f"æª¢æ¸¬åˆ°è‚¡ç¥¨ä»£è™Ÿ {valid_symbols}ï¼Œè‡ªå‹•è¨­å®šç‚ºè‚¡ç¥¨å ±å‘Š")

    result["symbols"] = list(set(valid_symbols))

    # æå–ç¸½ç¶“æŒ‡æ¨™é—œéµè©
    macro_keywords = re.findall(r'\b(GDP|CPI|INFLATION|UNEMPLOYMENT|INTEREST|RATE)\b', content.upper())
    result["indicators"] = list(set(macro_keywords))

    # å…¶ä»–é—œéµè©
    result["keywords"] = content.split()

    logger.info(f"è¦å‰‡å¼è§£æçµæœ: {result}")
    return result


# ===== å ±å‘Šå»ºæ§‹å·¥å…· =====

async def tool_build_report(template_id: str, context: Dict[str, Any], output_formats: List[str] = None) -> Dict[str, Any]:
    """å ±å‘Šå»ºæ§‹å·¥å…·"""
    _ensure_imports()
    logger.info(f"å»ºæ§‹å ±å‘Š: {template_id}, æ ¼å¼: {output_formats}")

    if output_formats is None:
        output_formats = ["markdown", "pdf"]

    try:
        from app.services.report import report_service
        from app.settings import settings
        import markdown
        import weasyprint
        from pathlib import Path

        # ç”Ÿæˆæ™‚é–“æˆ³å’Œæª”æ¡ˆå
        timestamp = generate_timestamp()
        slug = context.get("slug", "report")

        # è¨­å®šè¼¸å‡ºç›®éŒ„
        output_dir = Path(settings.output_dir) / "reports"
        output_dir.mkdir(parents=True, exist_ok=True)

        # æº–å‚™æ¨¡æ¿è®Šæ•¸
        template_vars = {
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "timestamp": timestamp,
            "slug": slug,
            **context
        }

        # è¼‰å…¥æ¨¡æ¿
        try:
            template = report_service.get_template(template_id)
            if not template:
                return {
                    "ok": False,
                    "source": "REPORT",
                    "data": None,
                    "timestamp": datetime.now().isoformat(),
                    "logs": f"æ‰¾ä¸åˆ°æ¨¡æ¿: {template_id}",
                    "error": "template_not_found"
                }
        except Exception as e:
            return {
                "ok": False,
                "source": "REPORT",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": f"è¼‰å…¥æ¨¡æ¿å¤±æ•—: {str(e)}",
                "error": "template_load_failed"
            }

        # æ¸²æŸ“æ¨¡æ¿
        try:
            rendered_content = template.render(**template_vars)
        except Exception as e:
            return {
                "ok": False,
                "source": "REPORT",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": f"æ¨¡æ¿æ¸²æŸ“å¤±æ•—: {str(e)}",
                "error": "template_render_failed"
            }

        output_files = []

        # ç”Ÿæˆ Markdown æª”æ¡ˆ
        if "markdown" in output_formats:
            md_file = output_dir / f"{slug}.md"
            try:
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(rendered_content)

                output_files.append({
                    "format": "markdown",
                    "filename": f"{slug}.md",
                    "path": str(md_file),
                    "size": md_file.stat().st_size
                })
                logger.info(f"å·²ç”Ÿæˆ Markdown æª”æ¡ˆ: {md_file}")
            except Exception as e:
                logger.error(f"ç”Ÿæˆ Markdown æª”æ¡ˆå¤±æ•—: {str(e)}")

        # ç”Ÿæˆ PDF æª”æ¡ˆ
        if "pdf" in output_formats:
            try:
                pdf_file = output_dir / f"{slug}.pdf"

                # è½‰æ› Markdown ç‚º HTML
                html_content = markdown.markdown(rendered_content)

                # è¼‰å…¥ CSS æ¨£å¼
                css_path = Path(settings.pdf_default_css)
                css_content = ""
                if css_path.exists():
                    with open(css_path, 'r', encoding='utf-8') as f:
                        css_content = f.read()

                # å®Œæ•´ HTML
                full_html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{slug} å ±å‘Š</title>
    <style>{css_content}</style>
</head>
<body>
    {html_content}
</body>
</html>
"""

                # ç”Ÿæˆ PDF
                weasyprint.HTML(string=full_html).write_pdf(str(pdf_file))

                output_files.append({
                    "format": "pdf",
                    "filename": f"{slug}.pdf",
                    "path": str(pdf_file),
                    "size": pdf_file.stat().st_size
                })
                logger.info(f"å·²ç”Ÿæˆ PDF æª”æ¡ˆ: {pdf_file}")

            except ImportError:
                logger.warning("weasyprint æœªå®‰è£ï¼Œè·³é PDF ç”Ÿæˆ")
            except Exception as e:
                logger.error(f"ç”Ÿæˆ PDF æª”æ¡ˆå¤±æ•—: {str(e)}")

        # ç”Ÿæˆ PPTX æª”æ¡ˆï¼ˆå¯é¸ï¼‰
        if "pptx" in output_formats:
            try:
                from pptx import Presentation

                pptx_file = output_dir / f"{slug}.pptx"

                # å»ºç«‹ç°¡å–®çš„ PowerPoint
                prs = Presentation()
                slide = prs.slides.add_slide(prs.slide_layouts[0])
                title = slide.shapes.title
                content = slide.placeholders[1]

                title.text = f"{slug} å ±å‘Š"
                content.text = f"ç”Ÿæˆæ™‚é–“: {template_vars['generated_at']}\n\n{rendered_content[:500]}..."

                prs.save(str(pptx_file))

                output_files.append({
                    "format": "pptx",
                    "filename": f"{slug}.pptx",
                    "path": str(pptx_file),
                    "size": pptx_file.stat().st_size
                })
                logger.info(f"å·²ç”Ÿæˆ PPTX æª”æ¡ˆ: {pptx_file}")

            except ImportError:
                logger.warning("python-pptx æœªå®‰è£ï¼Œè·³é PPTX ç”Ÿæˆ")
            except Exception as e:
                logger.error(f"ç”Ÿæˆ PPTX æª”æ¡ˆå¤±æ•—: {str(e)}")

        return {
            "ok": True,
            "source": "REPORT",
            "data": {
                "files": output_files,
                "template_id": template_id,
                "slug": slug,
                "content_preview": rendered_content[:200] + "..." if len(rendered_content) > 200 else rendered_content
            },
            "timestamp": datetime.now().isoformat(),
            "logs": f"æˆåŠŸç”Ÿæˆ {len(output_files)} å€‹æª”æ¡ˆ"
        }

    except Exception as e:
        logger.error(f"å ±å‘Šå»ºæ§‹å¤±æ•—: {str(e)}")
        return {
            "ok": False,
            "source": "REPORT",
            "data": None,
            "timestamp": datetime.now().isoformat(),
            "logs": f"å ±å‘Šå»ºæ§‹å¤±æ•—: {str(e)}",
            "error": "build_failed"
        }


# ===== è¼”åŠ©å‡½æ•¸ =====

def generate_timestamp() -> str:
    """ç”Ÿæˆæ™‚é–“æˆ³è¨˜"""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def generate_slug(symbols: List[str], report_type: str) -> str:
    """ç”Ÿæˆæª”æ¡ˆåç¨± slug"""
    if symbols:
        # å–å‰å…©å€‹ symbol
        slug_symbols = symbols[:2]
        return "_".join(slug_symbols)
    else:
        return "CUSTOM" if report_type == "custom" else report_type.upper()


# ===== ç°¡åŒ–å ±å‘Šä»£ç†é¡ =====

class SimpleReportAgent:
    """ç°¡åŒ–å ±å‘Šä»£ç† - ä½¿ç”¨ç·šæ€§è™•ç†æµç¨‹å’Œ LLM è‡ªä¸»æ±ºç­–"""

    def __init__(self):
        _ensure_imports()
        self.llm = self._create_llm()
        logger.info("ç°¡åŒ–å ±å‘Šä»£ç†åˆå§‹åŒ–å®Œæˆ")

    def _create_llm(self):
        """å»ºç«‹ LLM å¯¦ä¾‹"""
        try:
            from app.settings import settings
            from langchain_openai import ChatOpenAI

            if settings.openai_api_key:
                return ChatOpenAI(
                    model="gpt-4o-mini",
                    api_key=settings.openai_api_key,
                    temperature=0.3
                )
            elif settings.azure_openai_api_key and settings.azure_openai_endpoint:
                return ChatOpenAI(
                    model=settings.azure_openai_deployment,
                    api_key=settings.azure_openai_api_key,
                    azure_endpoint=settings.azure_openai_endpoint,
                    api_version=settings.azure_openai_api_version,
                    temperature=0.3
                )
            else:
                logger.warning("æœªè¨­å®š OpenAI æˆ– Azure OpenAI API é‡‘é‘°ï¼ŒLLM å¢å¼·åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
                return None
        except ImportError:
            logger.warning("æœªå®‰è£ langchain_openaiï¼ŒLLM å¢å¼·åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            return None

    async def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œå ±å‘Šç”Ÿæˆ - ç·šæ€§è™•ç†æµç¨‹"""
        try:
            logger.info("é–‹å§‹åŸ·è¡Œç°¡åŒ–å ±å‘Šç”Ÿæˆæµç¨‹")

            # 1. è§£ææŸ¥è©¢
            query = input_data["query"]
            session_id = input_data.get("session_id", "simple_report")

            # ä½¿ç”¨ LLM æ™ºèƒ½è§£ææŸ¥è©¢
            parsed_query = await parse_report_query_with_llm(query, self.llm)

            # ç”Ÿæˆæ™‚é–“æˆ³å’Œ slug
            timestamp = generate_timestamp()
            slug = generate_slug(parsed_query["symbols"], parsed_query["report_type"])

            logger.info(f"æŸ¥è©¢è§£æå®Œæˆ: é¡å‹={parsed_query['report_type']}, è‚¡ç¥¨ä»£è™Ÿ={parsed_query['symbols']}")

            # 2. æ”¶é›†è³‡æ–™
            context = await self._collect_data(parsed_query)
            context["parsed_query"] = parsed_query
            context["slug"] = slug
            context["symbols"] = parsed_query["symbols"]

            logger.info("è³‡æ–™æ”¶é›†å®Œæˆ")

            # 3. é¸æ“‡æ¨¡æ¿
            template_id = self._select_template(parsed_query["report_type"])

            logger.info(f"å·²é¸æ“‡æ¨¡æ¿: {template_id}")

            # 4. LLM å¢å¼·åˆ†æï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.llm:
                try:
                    enhanced_context = await self._enhance_context_with_llm(context, template_id)
                    context.update(enhanced_context)
                    logger.info("LLM å¢å¼·åˆ†æå®Œæˆ")
                except Exception as e:
                    logger.warning(f"LLM å¢å¼·åˆ†æå¤±æ•—ï¼Œä½¿ç”¨åŸå§‹è³‡æ–™: {str(e)}")

            # 5. å»ºæ§‹å ±å‘Š
            output_formats = ["markdown", "pdf"]
            report_result = await tool_build_report(template_id, context, output_formats)

            if not report_result.get("ok"):
                raise Exception(f"å ±å‘Šå»ºæ§‹å¤±æ•—: {report_result.get('logs', 'æœªçŸ¥éŒ¯èª¤')}")

            # 6. å»ºæ§‹å›æ‡‰
            output_files = report_result["data"]["files"]

            # ç”Ÿæˆå›æ‡‰è¨Šæ¯
            response_message = self._generate_response_message(parsed_query, output_files, context)

            return {
                "ok": True,
                "response": response_message,
                "input_type": input_data["input_type"],
                "query": query,
                "output_files": output_files,
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "trace_id": input_data.get("trace_id", "")
            }

        except Exception as e:
            logger.error(f"ç°¡åŒ–å ±å‘Šä»£ç†åŸ·è¡Œå¤±æ•—: {str(e)}")
            return {
                "ok": False,
                "response": f"å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}",
                "input_type": input_data["input_type"],
                "query": input_data["query"],
                "output_files": [],
                "session_id": input_data.get("session_id"),
                "timestamp": datetime.now().isoformat(),
                "trace_id": input_data.get("trace_id", ""),
                "error": str(e)
            }

    async def _collect_data(self, parsed_query: Dict[str, Any]) -> Dict[str, Any]:
        """æ”¶é›†è³‡æ–™"""
        from app.settings import settings

        context = {}
        report_type = parsed_query["report_type"]
        symbols = parsed_query["symbols"]

        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨å·¥å…·åŸ·è¡Œ
        if not settings.execute_tools:
            logger.warning("å·¥å…·åŸ·è¡Œå·²åœç”¨")
            context["error"] = {
                "ok": False,
                "source": "SYSTEM",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": "å·¥å…·åŸ·è¡Œå·²åœç”¨",
                "error": "execute_tools_disabled"
            }
            return context

        try:
            # æ ¹æ“šå ±å‘Šé¡å‹æ”¶é›†è³‡æ–™
            if report_type == "stock" and symbols:
                logger.info(f"æ”¶é›†è‚¡ç¥¨è³‡æ–™: {symbols}")

                # ç²å–å ±åƒ¹
                quotes_result = await _agent_tool_fmp_quote.ainvoke({"symbols": symbols})
                context["quotes"] = self._wrap_tool_result(quotes_result, "FMP")

                # ç²å–å…¬å¸åŸºæœ¬é¢
                profiles_result = await _agent_tool_fmp_profile.ainvoke({"symbols": symbols})
                context["profiles"] = self._wrap_tool_result(profiles_result, "FMP")

                # ç²å–æ–°è
                news_result = await _agent_tool_fmp_news.ainvoke({"symbols": symbols, "limit": 10})
                context["news"] = self._wrap_tool_result(news_result, "FMP")

            elif report_type == "macro":
                logger.info("æ”¶é›†ç¸½ç¶“è³‡æ–™")
                indicators = parsed_query.get("indicators", ["GDP", "CPI", "UNEMPLOYMENT"])

                # æ”¶é›†ç¸½ç¶“è³‡æ–™
                macro_data = {}
                for indicator in indicators:
                    try:
                        result = await _agent_tool_fmp_macro.ainvoke({"indicator": indicator, "country": "US"})
                        if result.get("ok"):
                            macro_data[f"{indicator}_US"] = result.get("data", [])
                        else:
                            logger.warning(f"ç¸½ç¶“æŒ‡æ¨™ {indicator} æŸ¥è©¢å¤±æ•—")
                            macro_data[f"{indicator}_US"] = []
                    except Exception as e:
                        logger.error(f"ç¸½ç¶“æŒ‡æ¨™ {indicator} æŸ¥è©¢ç•°å¸¸: {str(e)}")
                        macro_data[f"{indicator}_US"] = []

                context["macro"] = {
                    "ok": True,
                    "source": "FMP",
                    "data": macro_data,
                    "timestamp": datetime.now().isoformat(),
                    "logs": f"æŸ¥è©¢ {len(indicators)} å€‹ç¸½ç¶“æŒ‡æ¨™"
                }

                # ä¹Ÿæ”¶é›†ç›¸é—œæ–°è
                news_result = await _agent_tool_fmp_news.ainvoke({"symbols": [], "limit": 5})
                context["news"] = self._wrap_tool_result(news_result, "FMP")

            elif report_type == "news":
                logger.info("æ”¶é›†æ–°èè³‡æ–™")
                news_result = await _agent_tool_fmp_news.ainvoke({"symbols": symbols, "limit": 15})
                context["news"] = self._wrap_tool_result(news_result, "FMP")

            else:
                logger.info("è‡ªè¨‚å ±å‘Šï¼Œæ”¶é›†åŸºæœ¬è³‡æ–™")
                if symbols:
                    quotes_result = await _agent_tool_fmp_quote.ainvoke({"symbols": symbols})
                    context["quotes"] = self._wrap_tool_result(quotes_result, "FMP")

            # å˜—è©¦ RAG æŸ¥è©¢ï¼ˆå¯é¸ï¼‰
            try:
                keywords = " ".join(parsed_query.get("keywords", []))
                if keywords:
                    rag_result = await _agent_tool_rag_query.ainvoke({"question": keywords, "top_k": 5})
                    context["rag"] = self._wrap_tool_result(rag_result, "RAG")
            except Exception as e:
                logger.warning(f"RAG æŸ¥è©¢å¤±æ•—: {str(e)}")
                context["rag"] = {
                    "ok": False,
                    "source": "RAG",
                    "data": None,
                    "timestamp": datetime.now().isoformat(),
                    "logs": f"RAG æŸ¥è©¢å¤±æ•—: {str(e)}",
                    "error": "query_failed"
                }

        except Exception as e:
            logger.warning(f"è³‡æ–™æ”¶é›†éç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸: {str(e)}")
            context["error"] = {
                "ok": False,
                "source": "SYSTEM",
                "data": None,
                "timestamp": datetime.now().isoformat(),
                "logs": f"è³‡æ–™æ”¶é›†ç•°å¸¸: {str(e)}",
                "error": "data_collection_failed"
            }

        return context

    def _wrap_tool_result(self, result: Dict[str, Any], source: str) -> Dict[str, Any]:
        """åŒ…è£å·¥å…·çµæœä»¥ä¿æŒæ ¼å¼ä¸€è‡´æ€§"""
        return {
            "ok": result.get("ok", False),
            "source": source,
            "data": result.get("data"),
            "timestamp": datetime.now().isoformat(),
            "logs": result.get("logs", ""),
            "error": result.get("reason") if not result.get("ok") else None
        }

    def _select_template(self, report_type: str) -> str:
        """é¸æ“‡å ±å‘Šæ¨¡æ¿"""
        from app.settings import settings

        # æ¨¡æ¿æ˜ å°„
        template_mapping = {
            "stock": "stock.j2",
            "macro": "macro.j2",
            "news": "news.j2",
            "custom": "custom.j2"
        }

        base_template_id = template_mapping.get(report_type, "custom.j2")

        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ LLM å¢å¼·ä¸¦é¸æ“‡å°æ‡‰æ¨¡æ¿
        if settings.llm_report_enhancement and report_type == "stock":
            # å°æ–¼è‚¡ç¥¨å ±å‘Šï¼Œå¦‚æœå•Ÿç”¨ LLM å¢å¼·ï¼Œä½¿ç”¨å¢å¼·æ¨¡æ¿
            template_id = "stock_llm_enhanced.j2"
            logger.info(f"LLM å¢å¼·å·²å•Ÿç”¨ï¼Œä½¿ç”¨å¢å¼·æ¨¡æ¿: {template_id}")
        elif report_type == "stock":
            # å³ä½¿ LLM å¢å¼·æœªå•Ÿç”¨ï¼Œè‚¡ç¥¨å ±å‘Šä¹Ÿä½¿ç”¨å¢å¼·æ¨¡æ¿ï¼ˆæä¾›æ›´å¥½çš„çµæ§‹ï¼‰
            template_id = "stock_llm_enhanced.j2"
            logger.info(f"è‚¡ç¥¨å ±å‘Šä½¿ç”¨å¢å¼·æ¨¡æ¿ï¼ˆçµæ§‹æ›´å®Œæ•´ï¼‰: {template_id}")
        else:
            template_id = base_template_id
            logger.info(f"ä½¿ç”¨åŸºç¤æ¨¡æ¿: {template_id}")

        return template_id

    async def _enhance_context_with_llm(self, context: Dict[str, Any], template_id: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM å¢å¼·å ±å‘Šä¸Šä¸‹æ–‡ - åŸºæ–¼å¯¦éš›è³‡æ–™é€²è¡Œæ·±åº¦åˆ†æ"""
        try:
            if not self.llm:
                logger.warning("LLM æœªè¨­å®šï¼Œè·³éå¢å¼·åˆ†æ")
                return {}

            # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„è³‡æ–™é€²è¡Œåˆ†æ
            has_data = any([
                context.get("quotes", {}).get("ok"),
                context.get("profiles", {}).get("ok"),
                context.get("news", {}).get("ok"),
                context.get("macro", {}).get("ok")
            ])

            if not has_data:
                logger.warning("æ²’æœ‰å¯ç”¨çš„è³‡æ–™é€²è¡Œ LLM åˆ†æ")
                return {
                    "market_analysis": "ç”±æ–¼ç¼ºä¹è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œè©³ç´°çš„å¸‚å ´åˆ†æ",
                    "fundamental_analysis": "éœ€è¦æ›´å¤šå…¬å¸åŸºæœ¬é¢è³‡æ–™æ‰èƒ½é€²è¡Œåˆ†æ",
                    "news_impact": "æ²’æœ‰ç›¸é—œæ–°èè³‡æ–™å¯ä¾›åˆ†æ",
                    "investment_recommendation": "è³‡æ–™ä¸è¶³ï¼Œå»ºè­°è¬¹æ…æŠ•è³‡",
                    "risk_assessment": "ç”±æ–¼è³‡æ–™é™åˆ¶ï¼Œé¢¨éšªè©•ä¼°å¯èƒ½ä¸å®Œæ•´",
                    "key_insights": ["è³‡æ–™æ”¶é›†å—é™ï¼Œå»ºè­°ç²å–æ›´å¤šè³‡è¨Šå¾Œå†åšæ±ºç­–"]
                }

            # å»ºæ§‹è©³ç´°çš„åˆ†ææç¤º
            prompt = self._build_analysis_prompt(context, template_id)
            logger.info(f"å»ºæ§‹ LLM åˆ†ææç¤ºï¼Œé•·åº¦: {len(prompt)} å­—ç¬¦")

            # å»ºç«‹è¨Šæ¯
            system_prompt = """ä½ æ˜¯è³‡æ·±çš„é‡‘èåˆ†æå¸«ï¼Œå…·æœ‰è±å¯Œçš„è‚¡ç¥¨åˆ†æç¶“é©—ã€‚

è«‹åŸºæ–¼æä¾›çš„å¯¦éš›è³‡æ–™é€²è¡Œå°ˆæ¥­åˆ†æï¼š
1. åƒ…ä½¿ç”¨æä¾›çš„çœŸå¯¦è³‡æ–™ï¼Œä¸è¦æœæ’°ä»»ä½•æ•¸æ“š
2. æä¾›å…·é«”ã€å¯æ“ä½œçš„åˆ†æå’Œå»ºè­°
3. å¼•ç”¨å…·é«”çš„æ•¸æ“šé»æ”¯æŒä½ çš„åˆ†æ
4. ä¿æŒå®¢è§€å’Œå°ˆæ¥­çš„åˆ†ææ…‹åº¦
5. å¿…é ˆè¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼

åˆ†ææ‡‰è©²å…·é«”ä¸”å¯¦ç”¨ï¼Œé¿å…ä½¿ç”¨æ¨¡ç³Šæˆ–é€šç”¨çš„è¡¨è¿°ã€‚"""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=prompt)
            ]

            # èª¿ç”¨ LLM
            from app.settings import settings
            logger.info("é–‹å§‹èª¿ç”¨ LLM é€²è¡Œæ·±åº¦åˆ†æ...")

            response = await self.llm.ainvoke(
                messages,
                temperature=settings.llm_analysis_temperature,
                max_tokens=settings.llm_analysis_max_tokens
            )

            logger.info(f"LLM éŸ¿æ‡‰é•·åº¦: {len(response.content)} å­—ç¬¦")

            # è§£æ LLM éŸ¿æ‡‰
            try:
                # æ¸…ç†éŸ¿æ‡‰å…§å®¹ï¼Œç§»é™¤å¯èƒ½çš„ markdown æ¨™è¨˜
                content = response.content.strip()
                if content.startswith("```json"):
                    content = content[7:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()

                analysis_result = json.loads(content)
                logger.info("æˆåŠŸè§£æ LLM JSON éŸ¿æ‡‰")

                # é©—è­‰å¿…è¦æ¬„ä½
                required_fields = ["market_analysis", "fundamental_analysis", "news_impact",
                                 "investment_recommendation", "risk_assessment", "key_insights"]

                for field in required_fields:
                    if field not in analysis_result:
                        logger.warning(f"LLM éŸ¿æ‡‰ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
                        analysis_result[field] = f"åˆ†æä¸­ç¼ºå°‘ {field} å…§å®¹"

                # æå–å¢å¼·è³‡æ–™
                enhanced_data = {
                    "llm_analysis": analysis_result,
                    "market_analysis": analysis_result.get("market_analysis", ""),
                    "fundamental_analysis": analysis_result.get("fundamental_analysis", ""),
                    "news_impact": analysis_result.get("news_impact", ""),
                    "investment_recommendation": analysis_result.get("investment_recommendation", ""),
                    "risk_assessment": analysis_result.get("risk_assessment", ""),
                    "key_insights": analysis_result.get("key_insights", [])
                }

                logger.info("LLM å¢å¼·åˆ†ææˆåŠŸå®Œæˆ")
                return enhanced_data

            except json.JSONDecodeError as e:
                logger.warning(f"LLM éŸ¿æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„ JSON: {str(e)}")
                logger.warning(f"åŸå§‹éŸ¿æ‡‰å…§å®¹: {response.content[:500]}...")

                # å˜—è©¦å¾æ–‡å­—ä¸­æå–æœ‰ç”¨ä¿¡æ¯
                content = response.content
                return {
                    "llm_analysis": content,
                    "market_analysis": f"åŸºæ–¼ LLM åˆ†æï¼š{content[:200]}..." if len(content) > 200 else content,
                    "fundamental_analysis": "LLM åˆ†æçµæœæ ¼å¼ç•°å¸¸ï¼Œè«‹æª¢æŸ¥åŸå§‹åˆ†æå…§å®¹",
                    "news_impact": "ç„¡æ³•è§£ææ–°èå½±éŸ¿è©•ä¼°",
                    "investment_recommendation": "å»ºè­°æŸ¥çœ‹åŸå§‹ LLM åˆ†æå…§å®¹",
                    "risk_assessment": "é¢¨éšªè©•ä¼°è§£æå¤±æ•—",
                    "key_insights": ["LLM éŸ¿æ‡‰æ ¼å¼ç•°å¸¸", "å»ºè­°æª¢æŸ¥åŸå§‹åˆ†æå…§å®¹"]
                }

        except Exception as e:
            logger.error(f"LLM å¢å¼·åˆ†æå¤±æ•—: {str(e)}")
            import traceback
            logger.error(f"éŒ¯èª¤è©³æƒ…: {traceback.format_exc()}")

            return {
                "market_analysis": f"LLM åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                "fundamental_analysis": "åˆ†ææœå‹™æš«æ™‚ä¸å¯ç”¨",
                "news_impact": "ç„¡æ³•è©•ä¼°æ–°èå½±éŸ¿",
                "investment_recommendation": "å»ºè­°ç­‰å¾…åˆ†ææœå‹™æ¢å¾©å¾Œå†åšæ±ºç­–",
                "risk_assessment": "ç”±æ–¼æŠ€è¡“å•é¡Œï¼Œé¢¨éšªè©•ä¼°ä¸å¯ç”¨",
                "key_insights": ["åˆ†ææœå‹™ç•°å¸¸", "å»ºè­°ç¨å¾Œé‡è©¦"]
            }

    def _build_analysis_prompt(self, context: Dict[str, Any], template_id: str) -> str:
        """å»ºæ§‹ LLM åˆ†ææç¤º - åŒ…å«å¯¦éš›è³‡æ–™å…§å®¹"""
        symbols = context.get("symbols", [])

        prompt_parts = [
            f"ä½ æ˜¯å°ˆæ¥­çš„é‡‘èåˆ†æå¸«ã€‚è«‹åŸºæ–¼ä»¥ä¸‹å¯¦éš›è³‡æ–™é€²è¡Œæ·±åº¦åˆ†æï¼Œä¸¦æä¾›çµæ§‹åŒ–çš„ JSON éŸ¿æ‡‰ï¼š",
            f"è‚¡ç¥¨ä»£è™Ÿ: {', '.join(symbols) if symbols else 'ç„¡'}",
            f"æ¨¡æ¿é¡å‹: {template_id}",
            f"åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "=== å¯¦éš›è³‡æ–™å…§å®¹ ==="
        ]

        # æ·»åŠ è‚¡åƒ¹è³‡æ–™è©³æƒ…
        if context.get("quotes", {}).get("ok") and context["quotes"].get("data"):
            prompt_parts.append("\nğŸ“Š è‚¡åƒ¹è³‡æ–™:")
            quotes_data = context["quotes"]["data"]
            if isinstance(quotes_data, list):
                for quote in quotes_data[:3]:  # é™åˆ¶å‰3å€‹
                    if isinstance(quote, dict):
                        symbol = quote.get("symbol", "N/A")
                        price = quote.get("price", "N/A")
                        change = quote.get("change", "N/A")
                        change_pct = quote.get("changesPercentage", "N/A")
                        volume = quote.get("volume", "N/A")
                        day_low = quote.get("dayLow", "N/A")
                        day_high = quote.get("dayHigh", "N/A")

                        prompt_parts.append(f"- {symbol}: åƒ¹æ ¼ ${price}, æ¼²è·Œ {change} ({change_pct}%), æˆäº¤é‡ {volume}")
                        prompt_parts.append(f"  æ—¥å…§å€é–“: ${day_low} - ${day_high}")

        # æ·»åŠ å…¬å¸åŸºæœ¬é¢è³‡æ–™è©³æƒ…
        if context.get("profiles", {}).get("ok") and context["profiles"].get("data"):
            prompt_parts.append("\nğŸ¢ å…¬å¸åŸºæœ¬é¢:")
            profiles_data = context["profiles"]["data"]
            if isinstance(profiles_data, list):
                for profile in profiles_data[:3]:  # é™åˆ¶å‰3å€‹
                    if isinstance(profile, dict):
                        symbol = profile.get("symbol", "N/A")
                        company_name = profile.get("companyName", "N/A")
                        industry = profile.get("industry", "N/A")
                        sector = profile.get("sector", "N/A")
                        market_cap = profile.get("mktCap", "N/A")
                        description = profile.get("description", "")[:200] + "..." if profile.get("description") else "N/A"

                        prompt_parts.append(f"- {symbol} ({company_name})")
                        prompt_parts.append(f"  ç”¢æ¥­: {industry}, éƒ¨é–€: {sector}")
                        prompt_parts.append(f"  å¸‚å€¼: {market_cap}")
                        prompt_parts.append(f"  æè¿°: {description}")

        # æ·»åŠ æ–°èè³‡æ–™è©³æƒ…
        if context.get("news", {}).get("ok") and context["news"].get("data"):
            prompt_parts.append("\nğŸ“° ç›¸é—œæ–°è:")
            news_data = context["news"]["data"]
            if isinstance(news_data, list):
                for i, news in enumerate(news_data[:5], 1):  # é™åˆ¶å‰5æ¢æ–°è
                    if isinstance(news, dict):
                        title = news.get("title", "N/A")
                        text = news.get("text", "")[:150] + "..." if news.get("text") else "N/A"
                        published_date = news.get("publishedDate", "N/A")
                        site = news.get("site", "N/A")

                        prompt_parts.append(f"{i}. {title}")
                        prompt_parts.append(f"   ä¾†æº: {site}, æ™‚é–“: {published_date}")
                        prompt_parts.append(f"   æ‘˜è¦: {text}")

        # æ·»åŠ ç¸½ç¶“è³‡æ–™è©³æƒ…ï¼ˆå¦‚æœæœ‰ï¼‰
        if context.get("macro", {}).get("ok") and context["macro"].get("data"):
            prompt_parts.append("\nğŸ“ˆ ç¸½ç¶“è³‡æ–™:")
            macro_data = context["macro"]["data"]
            if isinstance(macro_data, dict):
                for indicator, data in macro_data.items():
                    if data and isinstance(data, list):
                        latest = data[0] if data else {}
                        if isinstance(latest, dict):
                            value = latest.get("value", "N/A")
                            date = latest.get("date", "N/A")
                            prompt_parts.append(f"- {indicator}: {value} (æˆªè‡³ {date})")

        prompt_parts.extend([
            "",
            "=== åˆ†æè¦æ±‚ ===",
            "è«‹åŸºæ–¼ä¸Šè¿°å¯¦éš›è³‡æ–™ï¼Œæä¾›æ·±åº¦ä¸”å…·é«”çš„åˆ†æã€‚é¿å…ä½¿ç”¨é€šç”¨æˆ–æ¨¡ç³Šçš„è¡¨è¿°ã€‚",
            "æ¯å€‹åˆ†æé …ç›®æ‡‰è©²ï¼š",
            "1. å¼•ç”¨å…·é«”çš„æ•¸æ“šé»",
            "2. æä¾›æ˜ç¢ºçš„åˆ¤æ–·å’Œç†ç”±",
            "3. çµ¦å‡ºå¯æ“ä½œçš„å»ºè­°",
            "",
            "è«‹æä¾›ä»¥ä¸‹ JSON æ ¼å¼çš„åˆ†æï¼š",
            "{",
            '  "market_analysis": "åŸºæ–¼è‚¡åƒ¹è¡¨ç¾ã€æˆäº¤é‡ã€æ¼²è·Œå¹…ç­‰æ•¸æ“šçš„å…·é«”å¸‚å ´åˆ†æ",',
            '  "fundamental_analysis": "åŸºæ–¼å…¬å¸åŸºæœ¬é¢è³‡æ–™çš„å…·é«”åˆ†æï¼ŒåŒ…æ‹¬ç”¢æ¥­åœ°ä½ã€å¸‚å€¼è©•ä¼°ç­‰",',
            '  "news_impact": "åŸºæ–¼å¯¦éš›æ–°èå…§å®¹çš„å½±éŸ¿è©•ä¼°ï¼Œåˆ†ææ­£é¢/è² é¢å› ç´ ",',
            '  "investment_recommendation": "åŸºæ–¼ç¶œåˆåˆ†æçš„å…·é«”æŠ•è³‡å»ºè­°ï¼ŒåŒ…æ‹¬ç›®æ¨™åƒ¹ä½æˆ–æ“ä½œç­–ç•¥",',
            '  "risk_assessment": "åŸºæ–¼ç•¶å‰å¸‚æ³å’Œå…¬å¸ç‹€æ³çš„å…·é«”é¢¨éšªè©•ä¼°",',
            '  "key_insights": ["åŸºæ–¼æ•¸æ“šçš„é—œéµæ´å¯Ÿ1", "åŸºæ–¼æ•¸æ“šçš„é—œéµæ´å¯Ÿ2", "åŸºæ–¼æ•¸æ“šçš„é—œéµæ´å¯Ÿ3"]',
            "}"
        ])

        return "\n".join(prompt_parts)

    def _generate_response_message(self, parsed_query: Dict[str, Any], output_files: List[Dict[str, Any]], context: Dict[str, Any]) -> str:
        """ç”Ÿæˆå›æ‡‰è¨Šæ¯"""
        report_type = parsed_query["report_type"]
        symbols = parsed_query["symbols"]

        # åŸºæœ¬è¨Šæ¯
        message_parts = [
            f"ğŸ“Š {report_type.upper()} å ±å‘Šç”Ÿæˆå®Œæˆï¼",
            ""
        ]

        # å ±å‘Šè©³æƒ…
        if symbols:
            message_parts.append(f"ğŸ¯ åˆ†ææ¨™çš„ï¼š{', '.join(symbols)}")

        message_parts.append(f"ğŸ“ å ±å‘Šé¡å‹ï¼š{report_type}")
        message_parts.append(f"ğŸ•’ ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        message_parts.append("")

        # è³‡æ–™ä¾†æºæ‘˜è¦
        data_sources = []
        for key, value in context.items():
            if isinstance(value, dict) and "ok" in value:
                status = "âœ…" if value["ok"] else "âŒ"
                source_name = value.get("source", key.upper())
                data_sources.append(f"{status} {source_name}")

        if data_sources:
            message_parts.append("ğŸ“Š è³‡æ–™ä¾†æºï¼š")
            message_parts.extend([f"  {source}" for source in data_sources])
            message_parts.append("")

        # è¼¸å‡ºæª”æ¡ˆ
        if output_files:
            message_parts.append("ğŸ“„ ç”Ÿæˆæª”æ¡ˆï¼š")
            for file_info in output_files:
                format_name = file_info["format"].upper()
                file_path = file_info["path"]
                message_parts.append(f"  â€¢ {format_name}: {file_path}")
            message_parts.append("")

        # è§£ææ–¹æ³•è³‡è¨Š
        parsing_method = parsed_query.get("parsing_method", "unknown")
        confidence = parsed_query.get("confidence", 0.0)

        if parsing_method == "llm":
            message_parts.append(f"ğŸ¤– æ™ºèƒ½è§£æï¼šLLM é©…å‹• (ä¿¡å¿ƒåº¦: {confidence:.1%})")
        else:
            message_parts.append(f"ğŸ”§ è¦å‰‡è§£æï¼šå‚™ç”¨æ–¹æ¡ˆ (ä¿¡å¿ƒåº¦: {confidence:.1%})")

        message_parts.append("")
        message_parts.append("âœ¨ å ±å‘Šå·²æº–å‚™å°±ç·’ï¼Œè«‹æŸ¥çœ‹ç”Ÿæˆçš„æª”æ¡ˆï¼")

        return "\n".join(message_parts)


# ===== å…¨åŸŸå¯¦ä¾‹ =====

# å…¨åŸŸç°¡åŒ–å ±å‘Šä»£ç†å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
simple_report_agent = None


def get_simple_report_agent() -> SimpleReportAgent:
    """å–å¾—å…¨åŸŸç°¡åŒ–å ±å‘Šä»£ç†å¯¦ä¾‹"""
    global simple_report_agent
    if simple_report_agent is None:
        simple_report_agent = SimpleReportAgent()
    return simple_report_agent


# ===== å‘å¾Œå…¼å®¹æ€§æ”¯æ´ =====

class ReportAgent:
    """å‘å¾Œå…¼å®¹çš„å ±å‘Šä»£ç†é¡ - å§”è¨—çµ¦ SimpleReportAgent"""

    def __init__(self):
        self.simple_agent = SimpleReportAgent()
        logger.info("å‘å¾Œå…¼å®¹å ±å‘Šä»£ç†åˆå§‹åŒ–å®Œæˆ")

    async def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œå ±å‘Šç”Ÿæˆ - å§”è¨—çµ¦ç°¡åŒ–ä»£ç†"""
        return await self.simple_agent.run(input_data)


# å…¨åŸŸå ±å‘Šä»£ç†å¯¦ä¾‹ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
report_agent = None


def get_report_agent() -> ReportAgent:
    """å–å¾—å…¨åŸŸå ±å‘Šä»£ç†å¯¦ä¾‹ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    global report_agent
    if report_agent is None:
        report_agent = ReportAgent()
    return report_agent


# ===== ç›´æ¥åŸ·è¡Œæ”¯æ´ =====

async def run_default_report_generation():
    """åŸ·è¡Œé è¨­å ±å‘Šç”Ÿæˆï¼ˆç„¡éœ€å‘½ä»¤åˆ—åƒæ•¸ï¼‰"""
    global simple_report_agent

    # åˆå§‹åŒ–ç°¡åŒ–å ±å‘Šä»£ç†ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
    if simple_report_agent is None:
        simple_report_agent = SimpleReportAgent()

    # ç¡¬ç·¨ç¢¼çš„é è¨­å€¼
    DEFAULT_QUERY = "/report stock AAPL TSLA NVDA"
    DEFAULT_OUTPUT_DIR = "./outputs"
    DEFAULT_FORMATS = ["markdown", "pdf"]

    print("ğŸ¤– ç°¡åŒ–å ±å‘Šä»£ç† - é è¨­å ±å‘Šç”Ÿæˆ")
    print(f"ğŸ“ æŸ¥è©¢ï¼š{DEFAULT_QUERY}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„ï¼š{DEFAULT_OUTPUT_DIR}")
    print(f"ğŸ“„ è¼¸å‡ºæ ¼å¼ï¼š{', '.join(DEFAULT_FORMATS)}")
    print()

    try:
        # æº–å‚™è¼¸å…¥è³‡æ–™
        input_data = {
            "input_type": "text",
            "query": DEFAULT_QUERY,
            "session_id": f"simple_report_{generate_timestamp()}",
            "trace_id": f"simple_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        }

        print("ğŸš€ é–‹å§‹åŸ·è¡Œå ±å‘Šç”Ÿæˆ...")

        # åŸ·è¡Œå ±å‘Šç”Ÿæˆ
        result = await simple_report_agent.run(input_data)

        # è™•ç†çµæœ
        if result.get("ok"):
            print("âœ… å ±å‘Šç”ŸæˆæˆåŠŸï¼")
            print()

            # é¡¯ç¤ºè¼¸å‡ºæª”æ¡ˆ
            output_files = result.get("output_files", [])
            if output_files:
                print("ğŸ“„ ç”Ÿæˆçš„æª”æ¡ˆï¼š")
                for file_info in output_files:
                    file_path = file_info.get("path", "æœªçŸ¥è·¯å¾‘")
                    file_format = file_info.get("format", "æœªçŸ¥æ ¼å¼")
                    print(f"  â€¢ {file_format.upper()}: {file_path}")

            # é¡¯ç¤ºå›æ‡‰å…§å®¹
            if result.get("response"):
                print()
                print("ğŸ“‹ å ±å‘Šæ‘˜è¦ï¼š")
                print(result["response"])

            return 0

        else:
            print("âŒ å ±å‘Šç”Ÿæˆå¤±æ•—")
            error_msg = result.get("error", "æœªçŸ¥éŒ¯èª¤")
            print(f"éŒ¯èª¤ï¼š{error_msg}")

            if result.get("response"):
                print()
                print("è©³ç´°è³‡è¨Šï¼š")
                print(result["response"])

            return 1

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
        return 130

    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
        return 1


# ===== ä¸»ç¨‹å¼å…¥å£ =====

if __name__ == "__main__":
    """ç›´æ¥åŸ·è¡Œæ”¯æ´"""
    import asyncio

    async def main():
        """ä¸»ç¨‹å¼"""
        try:
            exit_code = await run_default_report_generation()
            return exit_code
        except Exception as e:
            print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—ï¼š{str(e)}")
            return 1

    # åŸ·è¡Œä¸»ç¨‹å¼
    exit_code = asyncio.run(main())
    exit(exit_code)